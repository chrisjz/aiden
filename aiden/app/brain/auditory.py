import base64
import json
import os
import aiohttp
from fastapi import HTTPException
from typing import AsyncGenerator

from aiden import logger
from aiden.app.brain.cognition import AUDITORY_AMBIENT_URL_BASE
from aiden.models.brain import AuditoryRequest, AuditoryResponse, AuditoryResult


async def process_auditory(request: AuditoryRequest) -> AsyncGenerator[str, None]:
    """
    Simulates the primary auditory cortex by processing ambient noise inputs to classify sounds.

    Args:
        request (AuditoryRequest): The request containing the audio and configuration.

    Yields:
        str: Each chunk of the classification results as a string. These chunks are parts of
             the full classification result generated by the model, provided sequentially as they are generated.
    """
    top_n = os.environ.get("AUDITORY_AMBIENT_TOP_N", "1")
    audio_data = base64.b64decode(request.audio)

    # Determine file format (MP3 or WAV) by analyzing the first few bytes
    if audio_data.startswith(b"\xff\xf3") or audio_data.startswith(b"\xff\xfb"):
        # MP3 Magic bytes
        filename = "audio.mp3"
        content_type = "audio/mp3"
    elif audio_data.startswith(b"RIFF") and audio_data[8:12] == b"WAVE":
        # WAV Magic bytes
        filename = "audio.wav"
        content_type = "audio/wav"
    else:
        raise HTTPException(status_code=400, detail="Unsupported audio format")

    # Prepare the multipart form data
    form_data = aiohttp.FormData()
    form_data.add_field(
        "file", audio_data, filename=filename, content_type=content_type
    )

    # Set up the classification request
    classify_url = f"{AUDITORY_AMBIENT_URL_BASE}/classify"
    params = {"top_n": top_n}

    async with aiohttp.ClientSession() as session:
        try:
            async with session.post(
                classify_url, data=form_data, params=params
            ) as response:
                if response.status != 200:
                    raise HTTPException(
                        status_code=response.status, detail=await response.text()
                    )

                response_json = await response.json()
                auditory_response = AuditoryResponse(
                    results=[
                        AuditoryResult(class_name=item["class"], score=item["score"])
                        for item in response_json
                    ]
                )

                yield auditory_response.model_dump_json()

        except Exception as exc:
            error_message = json.dumps({"error": str(exc)})
            logger.error(f"Failed recognizing auditory input with error: {exc}")
            yield error_message
