import json
import os
from typing import AsyncGenerator

from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

from aiden import logger
from aiden.app.brain.cognition import VISION_API_URL_BASE
from aiden.app.utils import load_brain_config
from aiden.models.brain import OccipitalRequest


async def process_occipital(request: OccipitalRequest) -> AsyncGenerator[str, None]:
    """
    Processes visual inputs to generate a textual description using an asynchronous generator.

    Args:
        request (OccipitalRequest): The request containing the image and configuration.

    Yields:
        str: Each chunk of the rewritten sensory prompt as a string. These chunks are parts of
             the full description generated by the model, provided sequentially as they are generated.
    """
    brain_config = load_brain_config(request.config)
    instruction = "\n".join(brain_config.regions.occipital.instruction)

    messages = [HumanMessage(content=instruction, image=request.image)]

    llm = ChatOllama(
        base_url=VISION_API_URL_BASE,
        model=os.environ.get("VISION_MODEL", "bakllava"),
        timeout=30.0,
    )

    logger.info(f"Occipital chat message instruction: {instruction}")

    try:
        for chunk in llm.stream(messages):
            if chunk.content:
                yield chunk.content
            if hasattr(chunk, "done") and chunk.done:
                break
    except Exception as exc:
        error_message = json.dumps({"error": str(exc)})
        logger.error(f"Failed recognizing vision with error: {exc}")
        yield error_message
